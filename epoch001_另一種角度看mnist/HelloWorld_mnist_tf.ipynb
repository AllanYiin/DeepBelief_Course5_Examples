{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World mnist (tensorflow)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "支援python 版本: 3.5以上\n",
    "支援tensorflow版本 : 2.0以上"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "這次實作要使用的是深度學習界的Hello world也就是手寫數字數據集MNIST(別誤寫為MINIST歐)。MNIST 數據集來自美國國家標準與技術研究所, National Institute of Standards and Technology (NIST). 訓練集 (training set) 由來自 250 個不同人手寫的數字構成, 其中 50% 是高中學生, 50% 來自人口普查局 (the Census Bureau) 的工作人員. 測試集(test set) 也是同樣比例的手寫數字數據。基本上這個數據集毫無挑戰性，任何神經網路幾乎都能獲得很好的擬合效果，所以它也很常被做為新算法觀念驗證使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trident 0.5.0\n",
      "Using TensorFlow backend.\n",
      "Image Data Format: channels_last.\n",
      "Image Channel Order: rgb.\n",
      "Using pillow image backend.\n",
      "Pillow version:6.2.1.\n",
      "Tensorflow version:2.1.0.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'trident.models' has no attribute 'vgg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cd8436cf0527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TRIDENT_BACKEND'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtrident\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrident\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\azuremlenv\\lib\\site-packages\\trident\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.5.0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trident {0}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrident\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrident\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmisc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\azuremlenv\\lib\\site-packages\\trident\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0miteration_tools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m  \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'trident.models' has no attribute 'vgg'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "os.environ['TRIDENT_BACKEND'] = 'tensorflow'\n",
    "import trident as T\n",
    "from trident import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在我們這次一系列實作課程改版，很大的差異就是來自於有了新的API:trident,它的概念是提供不同框架的平行開發範本，讓跨框架的開發體驗都能一致化，同時透過封裝過的API，各位也就不需要在關注那些瑣碎的事，掉坑的可能性也會少一點。首先我們來看trident很重要的一個特性，那就是可以一行指令來獲取我們的數據集，我們這次有把經典數據集，以及我為了課程所設計的數據集進行封裝，以MNIST數據集為例，各位只要如下方的一行指令就能存取數據，再加一行就能完成數據的清洗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=T.load_mnist('mnist') #讀取mnist數據集\n",
    "dataset.image_transform_funcs=[normalize(127.5,127.5)] #在圖像預處理流程中加入正規化\n",
    "data,label=dataset.next()\n",
    "print(data.shape,label.shape)\n",
    "print(dataset.signature)\n",
    "\n",
    "img_list=[random.choice(dataset.get_all_data(is_shuffle=True)).reshape((28,28)) for i in range(10)]#從全體圖像數據(get_all_data())抽10筆\n",
    "                        \n",
    "merged_img=array2image(np.concatenate(img_list,axis=1)) #沿著x軸(axis=1)疊合後，利用array2image轉成圖檔\n",
    "\n",
    "\n",
    "merged_img #顯示圖片"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "你也可以透過簡單的將數據集名稱改成'fashion-mnist'，就能夠存取到難度略高一點點的fashion mnist數據集。他們都是由28*28的黑白圖片組成(攤平後為長度784)，類別數量都是10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdataset=T.load_mnist('fashion-mnist') #讀取fashion mnist數據集\n",
    "dataset.image_transform_funcs=[normalize(127.5,127.5)]  #在圖像預處理流程中加入正規化\n",
    "\n",
    "img_list2=[random.choice(fdataset.get_all_data(get_image_mode = GetImageMode.expect)) for i in range(10)]#從全體圖像數據(get_all_data())抽10筆               \n",
    "merged_img2=array2image(np.concatenate(img_list2,axis=1)) #沿著x軸(axis=1)疊合後，利用array2image轉成圖檔\n",
    "\n",
    "merged_img2 #顯示圖片"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我們很愛用MNIST的最重要原因就是在於它太簡單了，幾乎任何網路架構都能夠很好的被擬合，所以幾乎不會有做不出來的風險，我們目前先以最原始的全連接層來測試，同時要讓大家可以在這過程中驗證基礎深度學習訓練(最佳化)的重要概念。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "除了數據集容易取得外，trident的最大特性是它可以讓原本得寫class的pytroch，能夠用類似keras的語法簡化開發，但是配合我們新設計的trainer API，各位可以擁有更彈性的設定，不像keras透過封裝為fit, train_on_batch這幾種過度簡化的訓練流程，可以讓大家用極簡單的語法就能設計好模型，即使要加入客製化流程也非常簡單。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設計網路結構基礎型\n",
    "net1=Sequential(\n",
    "    Flatten(),\n",
    "    Dense(64,use_bias=False,activation='leaky_relu'),\n",
    "    Dense(32,use_bias=False,activation='leaky_relu'),\n",
    "    Dense(16,use_bias=False,activation='leaky_relu'),\n",
    "    Dense(2,use_bias=False,activation=None),\n",
    "    Dense(10,use_bias=False,activation='softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "以我們這次要用來跑MNIST的模型，基本上是5層全連接層，其中最後一層是對應到10 種類別，那麼為何倒數第二層的寬度為何只有2呢?這其實是我們等於故意做了一個寬度為2的窄門，強迫模型要壓縮特徵向量，將它降維至2，這樣我們等下就可以用來做一些有趣的視覺化。上面三層則是通道數逐層減半，老實說，你即使把三層縮成一層效果也不會太差，要做三層的原因則是等下我們要測試Dropout對訓練的影響。\n",
    "\n",
    "我們這邊要同時比較三個模型的訓練成效，剛剛看到的是基線模型，第二個模型的話最大的差異在於加入了Batch normalization，事實上[卷積->標準化->活化函數]這個三位一體的配方幾乎可以在所有的卷積神經網路中看到，我們來測測Batch normalization到底有甚麼神奇的效果。至於第三個模型，則是加入了Dropout，Dropout可是由深度學習之父Hinton所提出，看似有點瘋狂讓一半的神經元失去作用，但反而是鼓勵了網路構成高度備援且冗餘的權重組合，反而為訓練帶來的正面的影響。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入批次正規化\n",
    "net2=Sequential(\n",
    "    Flatten(),\n",
    "    Dense(64,use_bias=False,activation=None),\n",
    "    BatchNorm(affine=False),\n",
    "    LeakyRelu(),\n",
    "    Dense(32,use_bias=False,activation=None),\n",
    "    BatchNorm(affine=False),\n",
    "    LeakyRelu(),\n",
    "    Dense(16,use_bias=False,activation=None),\n",
    "    BatchNorm(affine=False),\n",
    "    LeakyRelu(),\n",
    "    Dense(2,use_bias=False,activation=None),\n",
    "    Dense(10,use_bias=False,activation='softmax'))\n",
    "\n",
    "#加入Dropout\n",
    "net3=Sequential(\n",
    "    Flatten(),\n",
    "    Dense(64,use_bias=False,activation=None),\n",
    "    BatchNorm(affine=False),\n",
    "    LeakyRelu(),\n",
    "    Dropout(0.5),\n",
    "    Dense(32,use_bias=False,activation=None),\n",
    "    BatchNorm(affine=False),\n",
    "    LeakyRelu(),\n",
    "    Dense(16,use_bias=False,activation=None),\n",
    "    BatchNorm(affine=False),\n",
    "    LeakyRelu(),\n",
    "    Dense(2,use_bias=False,activation=None),\n",
    "    Dense(10,use_bias=False,activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接著我們需要指定網路結構(輸出)以及對應的輸入就可以轉換成模型，同時指定對應的優化器、損失函數以及評估函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Model(input_shape=[28*28],output=net1)\\\n",
    "    .with_optimizer(optimizer='Ranger',lr=5e-4)\\\n",
    "    .with_loss(CrossEntropyLoss)\\\n",
    "    .with_metric(accuracy)\n",
    "\n",
    "model2=Model(input_shape=[28*28],output=net2)\\\n",
    "    .with_optimizer(optimizer='Ranger',lr=5e-4)\\\n",
    "    .with_loss(CrossEntropyLoss)\\\n",
    "    .with_metric(accuracy)\n",
    "\n",
    "model3=Model(input_shape=[28*28],output=net3)\\\n",
    "    .with_optimizer(optimizer='Ranger',lr=5e-4)\\\n",
    "    .with_loss(CrossEntropyLoss)\\\n",
    "    .with_metric(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我們可以利用summary來檢視模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()\n",
    "model2.summary()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在trident中，我們利用TrainingPlan的物件來控制整個訓練過程，一個TrainingPlan可以容納多個模型，所以我們可以把三個模型全部加進去，然後指定數據來源、批次大小以及需要每多少個批次列印一次訓練進度。最後可以透過only_steps函數來執行(only_steps通常用於短期訓練，且需要留存較細節的信息，例如梯度與權重歷程)。\n",
    "\n",
    "執行完成後會顯示建模歷程的loss以及metrics變化走勢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan=TrainingPlan()\\\n",
    "    .add_training_item(model1)\\\n",
    "    .add_training_item(model2)\\\n",
    "    .add_training_item(model3)\\\n",
    "    .with_data_loader(dataset)\\\n",
    "    .within_minibatch_size(128)\\\n",
    "    .print_progress_scheduling(500,unit='batch')\\\n",
    "\n",
    "plan.only_steps(num_steps=2500,collect_data_inteval=50,keep_weights_history=True,keep_gradient_history=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "各位有沒有發現，前面的神經網路結構的倒數第二層的通道數都是2，為什麼做那麼奇怪的設計，這其實等於是強迫神經網路把特徵降維至2，這樣我們就可以使用2D圖表來檢視分類的效果。Mnist總共10個分類，我們可以看看這10分類在特徵空間的分布會是如何?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plan.training_items[0].model[:4]\n",
    "#plan.training_items[1].model[:11]\n",
    "\n",
    "\n",
    "def centerloss_plot(plt,feat, labels,title=''):\n",
    "    \n",
    "    c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff',\n",
    "         '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n",
    "    for i in range(10):\n",
    "        plt.plot(feat[labels == i, 0], feat[labels == i, 1], '.', c=c[i])\n",
    "    plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], loc = 'upper right')\n",
    "    plt.xlim(xmin=feat[:,0].min(),xmax=feat[:, 0].max())\n",
    "    plt.ylim(ymin=feat[:,1].min(),ymax=feat[:, 1].max())\n",
    "    plt.title(title)\n",
    "    \n",
    "    \n",
    "    \n",
    "fig = plt.figure(figsize=(18,6)) \n",
    "plt.clf()\n",
    "plt.ion()  # is not None:\n",
    "for k in [1,2,3]:\n",
    "    plt.subplot(1, 3, k)\n",
    "    feats_result=[]\n",
    "    label_result=[]\n",
    "    fm=Sequential(plan.training_items[k-1].model[:-1])#取出指定model的從第一層到倒數第二層，將它置入於Sequentiqal中\n",
    "    for i,(data,label) in enumerate(dataset):\n",
    "        data=to_tensor(data)\n",
    "        feats=fm(data)\n",
    "        feats=to_numpy(feats)\n",
    "        label=np.argmax(label,-1)\n",
    "        feats_result.append(feats)\n",
    "        label_result.append(label)  \n",
    "        if i==10:\n",
    "            break\n",
    "\n",
    "    feats_result=np.concatenate(feats_result,axis=0)\n",
    "    label_result=np.concatenate(label_result,axis=0)\n",
    "    plt.title('model {0}'.format(i))\n",
    "    centerloss_plot(plt,feats_result,label_result)\n",
    "plt.ioff() \n",
    "display.display(plt.gcf())\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下來的步驟是取出三個模型的梯度變化歷程，都只看第一層(形狀為(28*28,64))，我們透過計算平均值消除掉axis=1，這樣形狀會變回28*28，然後把它reshape成正方形，我們就可以看到對應圖像空間的梯度變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_dict={}\n",
    "for i in  range(3):\n",
    "    grad_dict[i]=[]\n",
    "    for j in range(len(plan.training_items[i].gradients_history)):\n",
    "        grad_dict[i].append(to_numpy(plan.training_items[i].gradients_history[j][0]).copy().mean(1))\n",
    "        \n",
    "fig =plt.figure(figsize=(8,8))\n",
    "plt.clf()\n",
    "plt.ion()  \n",
    "for j in range(3):\n",
    "    for i in [1,2,3]:\n",
    "        plt.subplot(3,3, 3*j+i)\n",
    "        n=[0,len(grad_dict[i-1])//2,len(grad_dict[i-1])-1][j]\n",
    "        grad_grid=grad_dict[i-1][n].reshape([28,28])\n",
    "        plt.pcolor(grad_grid)\n",
    "        plt.title('model {0}  step:{1}'.format(i,n*50))\n",
    "        plt.axis(\"off\")\n",
    "plt.ioff() \n",
    "display.display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
